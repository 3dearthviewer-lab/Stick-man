<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Stickman Motion Tracker</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: black;
    }
    canvas {
      display: block;
    }
    #status {
      position: absolute;
      top: 10px;
      left: 10px;
      color: lime;
      font-family: sans-serif;
      font-size: 14px;
    }
  </style>
</head>
<body>
  <div id="status">Loading...</div>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    import { PoseLandmarker, FilesetResolver } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const status = document.getElementById("status");

    // Canvas size match screen
    function resizeCanvas() {
      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;
    }
    window.addEventListener("resize", resizeCanvas);
    resizeCanvas();

    // Camera access
    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user" }
      });
      video.srcObject = stream;
      video.play();
    }

    // Load PoseLandmarker
    const filesetResolver = await FilesetResolver.forVisionTasks(
      "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
    );
    const poseLandmarker = await PoseLandmarker.createFromOptions(filesetResolver, {
      baseOptions: {
        modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task",
        delegate: "GPU"
      },
      runningMode: "VIDEO",
      numPoses: 1
    });

    // Drawing stickman
    function drawStickman(landmarks) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      const scale = Math.min(canvas.width / video.videoWidth, canvas.height / video.videoHeight);
      const offsetX = (canvas.width - video.videoWidth * scale) / 2;
      const offsetY = (canvas.height - video.videoHeight * scale) / 2;

      function getPoint(i) {
        const p = landmarks[i];
        return {
          x: offsetX + p.x * video.videoWidth * scale,
          y: offsetY + p.y * video.videoHeight * scale
        };
      }

      const connections = [
        [11, 12], [11, 13], [13, 15], [15, 17], [15, 19], [15, 21], [17, 19],
        [12, 14], [14, 16], [16, 18], [16, 20], [16, 22], [18, 20],
        [11, 23], [12, 24], [23, 24], [23, 25], [25, 27], [27, 29], [27, 31],
        [24, 26], [26, 28], [28, 30], [28, 32], [30, 32]
      ];

      ctx.strokeStyle = "cyan";
      ctx.lineWidth = 4;
      ctx.lineCap = "round";

      for (const [a, b] of connections) {
        const p1 = getPoint(a);
        const p2 = getPoint(b);
        ctx.beginPath();
        ctx.moveTo(p1.x, p1.y);
        ctx.lineTo(p2.x, p2.y);
        ctx.stroke();
      }

      // Draw joints
      ctx.fillStyle = "white";
      for (let i = 0; i < landmarks.length; i++) {
        const p = getPoint(i);
        ctx.beginPath();
        ctx.arc(p.x, p.y, 5, 0, 2 * Math.PI);
        ctx.fill();
      }
    }

    // Main loop
    let lastTime = 0;
    async function predict(time) {
      const delta = time - lastTime;
      if (delta > 30) { // ~30 FPS
        lastTime = time;
        const results = await poseLandmarker.detectForVideo(video, performance.now());
        if (results.landmarks.length > 0) {
          drawStickman(results.landmarks[0]);
          status.textContent = "Tracking...";
        } else {
          status.textContent = "No body detected";
        }
      }
      requestAnimationFrame(predict);
    }

    await startCamera();
    video.addEventListener("loadedmetadata", () => {
      requestAnimationFrame(predict);
    });
  </script>
</body>
</html>
